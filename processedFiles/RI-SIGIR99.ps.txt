Comparing
Performance
Database
Selection
Algorithms
James
French
Allison
Powell
Jamie
Callan
Charles
Viles
Travis
Emmitt
Kevin
Prey
Dept
Computer
Science
Lambda
University
Virginia
Charlottesville
Computer
Science
Dept
Univ
Massachusetts
Amherst
School
Info
Library
Science
Univ
North
Carolina--Chapel
Hill
Chapel
Hill
Abstract
compare
performance
database
se­lection
algorithms
reported
literature
Their
perfor­mance
compared
using
common
testbed
designed
specif­ically
database
selection
techniques
testbed
de­composition
TREC/TIPSTER
data
into
subcol­lections
databases
from
testbed
were
ranked
using
both
gGlOSS
CORI
techniques
compared
baseline
derived
from
TREC
relevance
judgements
ex­amined
degree
which
CORI
gGlOSS
approximate
this
baseline
results
confirm
earlier
observation
that
gGlOSS
Ideal(l
ranks
estimate
relevance­
based
ranks
well
also
find
that
CORI
uniformly
bet­ter
estimator
relevance­based
ranks
than
gGlOSS
test
environment
used
this
study
Part
advantage
CORI
algorithm
explained
strong
correla­tion
between
gGlOSS
size­based
baseline
also
find
that
CORI
produces
consistently
accurate
rank­ings
testbeds
ranging
from
100--921
sites
However
given
level
recall
search
effort
appears
scale
linearly
with
number
databases
References
Allan
Callan
Croft
Ballesteros
Byrd
Swan
INQUERY
does
battle
with
TREC­6
Proc
TREC­6
Belkin
Kantor
Shaw
Com­bining
Evidence
Multiple
Query
Representations
Information
Retrieval
Information
Processing
Manage­ment
31(4):431--448
1995
Buckley
SMART
version
11.0
1992
ftp://ftp.cs.cornell.edu/pub/smart
Buckley
Allan
Salton
Automatic
routing
ad­hoc
retrieval
using
SMART
TREC
Proc
TREC­2
pages
45--56
1994
Buckley
Salton
Allan
Automatic
retrieval
with
locality
information
using
SMART
Proc
TREC­1
pages
59--72
1993
Callan
Croft
Broglio
TREC
TIP­
STER
experiments
with
INQUERY
Information
Processing
Management
31(3):327--343
1995
Callan
Croft
Searching
Distributed
Collections
with
Inference
Networks
Proc
SIGIR'95
pages
21--29
1995
Koushik
Shaw
odlin
Combining
Evidence
from
Multiple
Searches
Proc
TREC­1
pages
319--328
1992
French
Powell
Viles
Emmitt
Prey
Evaluating
Database
Selection
Techniques
Testbed
Experiment
Proc
SIGIR'98
pages
121--129
1998
French
Viles
Ensuring
Retrieval
Effectiveness
Distributed
Digital
Libraries
Journal
Visual
Commu­nication
Image
Representation
7(1):61--73
1996
Fuhr
Decision­Theoretic
Approach
Database
Selec­tion
Networked
Trans
Information
Systems
appear
Gibbons
Nonparametric
Methods
Quantative
Analysis
Holt
Rinehart
Winston
1976
Gravano
Garcia­Molina
Generalizing
GlOSS
Vector­Space
Databases
Broker
Hierarchies
Proc
VLDB'95
1995
Gravano
Garcia­Molina
Tomasic
GlOSS
Text­source
discovery
over
internet
Trans
Database
Systems
appear
Gravano
Garcia­Molina
Tomasic
Effec­tiveness
GlOSS
Text
Database
Discovery
Problem
Proc
SIGMOD'94
pages
126--137
1994
Harman
Overview
Fourth
Text
Retrieval
Confer­ence
TREC­4
Proc
TREC­4
1996
Callan
Croft
Measures
collection
ranking
evaluation
Technical
Report
TR­96­39
Computer
Science
Department
University
Massachusetts
1996
Moffat
Zobel
Information
Retrieval
Systems
Large
Document
Collections
Proc
TREC­3
pages
85--94
1995
Singhal
Buckley
Mitra
Pivoted
document
length
normalization
Proc
SIGIR'96
pages
21--29
1996
Viles
French
TREC4
Experiments
Using
Drift
Proc
TREC­4
1996
Viles
French
Dissemination
Collection
Wide
Information
Distributed
Inform
ation
Retrieval
System
Proc
SIGIR'95
pages
12--20
July
1995
Voorhees
Gupta
Johnson­Laird
Learning
Collection
Fusion
Strategies
Proc
SIGIR'95
pages
1995
Voorhees
Gupta
Johnson­Laird
Collec­tion
Fusion
Problem
Proc
TREC­3
pages
95--104
1995
Callan
Effective
Retrieval
with
Distributed
Collections
Proc
SIGIR'98
pages
112--120
1998
Yuwono
Server
Ranking
Distributed
Text
Retrieval
Systems
Internet
Proc
Conf
Database
Systems
Applications
pages
41--49
1997