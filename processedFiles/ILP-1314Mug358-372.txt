Learning
from
Positive
Data
Stephen
Muggleton
Oxford
University
Computing
Laboratory
Parks
Road
Oxford
United
Kingdom
Abstract
Gold
showed
1967
that
even
regular
grammars
exactly
identified
from
positive
examples
alone
Since
known
that
children
learn
natural
grammars
almost
exclusively
from
positives
examples
Gold’s
result
been
used
theoretical
support
Chomsky’s
theory
innate
human
linguistic
abilities
this
paper
results
presented
which
show
that
within
Bayesian
framework
only
grammars
also
logic
programs
learnable
with
arbitrarily
expected
error
from
positive
examples
only
addition
show
that
upper
bound
expected
error
learner
which
maximises
Bayes’
posterior
probability
when
learning
from
positive
examples
within
small
additive
term
which
does
same
from
mixture
positive
negative
examples
Inductive
Logic
Programming
implementation
described
which
avoids
pitfalls
greedy
search
global
optimisation
this
function
during
local
construction
individual
clauses
hypothesis
Results
testing
this
implementation
artificially-generated
data-sets
reported
These
results
agreement
with
theoretical
predictions
References
Angluin
Inference
reversible
languages
Journal
29:741—765
1982
Biermann
Feldman
synthesis
finite-state
machines
from
samples
their
behaviour
IEEE
Transactions
Computers
C(21):592—597
1972
Buntine
Theory
Learning
Classification
Rules
thesis
School
Computing
Science
University
Technology
Sydney
1990
Chomsky
Knowledge
language
nature
origin
Praeger
York
1986
First
published
1965
Gold
Language
identification
limit
Information
Control
10:447—
1967
Haussler
Kearns
Shapire
Bounds
sample
complexity
Bayesian
learning
using
information
theory
dimension
COLT
Proceedings
Annual
Workshop
Computational
Learning
Theory
pages
61—74
Mateo
1991
Morgan
Kauffmann
Haussler
Kearns
Shapire
Bounds
sample
complexity
Bayesian
learning
using
information
theory
dimension
Machine
Learning
Journal
14(1):83—113
1994
Mooney
Califf
Induction
first-order
decision
lists
Results
learning
past
tense
english
verbs
Journal
Artificial
Intelligence
Research
3:1—24
1995
Muggleton
Bayesian
inductive
logic
programming
Warmuth
editor
Proceedings
Seventh
Annual
Conference
Computational
Learning
Theory
pages
3—11
York
1994
Press
Muggleton
Inverse
entailment
Progol
Generation
Computing
13:245—
1995
Muggleton
Stochastic
logic
programs
Raedt
editor
Advances
Inductive
Logic
Programming
Press/Ohmsha
1996
Muggleton
Bain
Hayes-Michie
Micbie
experimental
comparison
human
machine
learning
formalisms
Proceedings
Sixth
International
Workshop
Machine
Learning
Altos
1989
Kaufmann
Muggleton
Page
learnability
model
universal
representations
Technical
Report
PRG-TR-3-94
Oxford
University
Computing
Laboratory
Oxford
1994
Pinker
Language
learnability
language
development
Harvard
University
Press
Cambridge
Mass
1984
Plotkin
note
inductive
generalisation
Meltzer
Michie
editors
Machine
Intelligence
pages
153—163
Edinburgh
University
Press
Edinburgh
1969
Quinlan
Cameron
Induction
logic
programs
FOIL
related
systems
Generation
Computing
13:287—312
1995
Raedt
Bruynooghe
theory
clausal
discovery
Proceedings
13th
International
Joint
Conference
Artificial
Intelligence
Morgan
Kaufmann
1993
Shinohara
Inductive
inference
monotonic
formal
systems
from
positive
data
Proceedings
first
international
workshop
algorithmic
learning
theory
Tokyo
1990
Ohmsha
Valiant
theory
learnable
Communications
27:1134—
1142
1984