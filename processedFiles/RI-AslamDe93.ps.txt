General
Bounds
Statistical
Query
Learning
Learning
with
Noise
Hypothesis
Boosting
Javed
Aslam
Laboratory
Computer
Science
Massachusetts
Institute
Technology
Cambridge
02139
Scott
Decatur
Aiken
Computation
Laboratory
Harvard
University
Cambridge
02138
Abstract
derive
general
bounds
complexity
learning
Statistical
Query
model
model
with
classification
noise
considering
problem
boosting
accuracy
weak
learning
algorithms
which
fall
within
Statis­tical
Query
model
This
model
introduced
Kearns
provide
general
framework
ef­ficient
learning
presence
classification
noise
first
show
general
scheme
boosting
ac­curacy
weak
learning
algorithms
proving
that
weak
learning
equivalent
strong
learn­
boosting
eficient
used
show
main
result
first
general
upper
bounds
complexity
strong
learning
Specifi­cally
derive
simultaneous
upper
bounds
with
spect
number
queries
O(log
Vapnik­Chervonenkis
dimension
query
space
O(log
inverse
minimum
tol­
erance
addition
show
that
these
general
upper
bounds
nearly
optimal
describing
class
learning
problems
which
simultane­ously
lower
bound
number
queries
by#251
inverse
minimum
tolerance
further
apply
boosting
results
model
learning
model
with
classification
noise
Since
nearly
learning
algorithms
cast
model
apply
boosting
tech­niques
convert
these
algorithms
into
highly
eficient
algorithms
simulating
these
eficient
algorithms
model
with
classification
noise
show
that
nearly
algorithms
converted
into
highly
eficient
algorithms
which
tolerate
classification
noise
give
upper
bound
sample
complexity
these
noise­tolerant
algorithms
which
nearly
optimal
with
respect
noise
rate
also
give
upper
bounds
space
com­plexity
hypothesis
size
show
that
these
measures
fact
independent
noise
rate
note
that
running
times
these
noise­tolerant
algorithms
eficient
This
sequence
simulations
also
demonstrates
that
possible
boost
accuracy
nearly
algorithms
even
presence
noise
This
provides
partial
answer
open
problem
Schapire
first
theoretical
evidence
empirical
re­sult
Drucker
Schapire
Simard
References
Dana
Angluin
Computational
learning
theory
Sur­vey
selected
bibliography
Proceedings
Twenty­Fourth
Annual
Symposium
Theory
Computing
pages
351--369
1992
Dana
Angluin
Philip
Laird
Learning
from
noisy
examples
Machine
Learning
2(4):343--370
1988
Scott
Decatur
Statistical
queries
faulty
oracles
Proceedings
Sixth
Annual
Workshop
Computational
Learning
Theory
Press
1993
Harris
Drucker
Robert
Schapire
Patrice
Simard
Improving
performance
neural
networks
using
boosting
algorithm
Advances
Neural
Informa­tion
Processing
Systems
Morgan
Kaufmann
1992
Andrzej
Ehrenfeucht
David
Haussler
Michael
Kearns
Leslie
Valiant
general
lower
bound
number
examples
needed
learning
Infor­mation
Computation
82(3):247--251
September
1989
Yoav
Freund
Boosting
weak
learning
algorithm
majority
Proceedings
Third
Annual
Work­shop
Computational
Learning
Theory
pages
Morgan
Kaufmann
1990
Yoav
Freund
improved
boosting
algorithm
implications
learning
complexity
Proceedings
Fifth
Annual
Workshop
Computational
Learning
Theory
pages
391--398
Press
1992
Yoav
Freund
Personal
communication
1993
Sally
Goldman
Michael
Kearns
Robert
Schapire
Exact
identification
circuits
using
fixed
points
amplification
functions
Proceedings
31st
Symposium
Foundations
Computer
Sci­ence
pages
193--202
IEEE
October
1990
Sally
Goldman
Michael
Kearns
Robert
Schapire
sample
complexity
weak
learning
Proceedings
COLT
pages
217--231
Morgan
Kaufmann
1990
David
Helmbold
Robert
Sloan
Manfred
War­muth
Learning
integer
lattices
SIAM
Journal
Computing
21(2):240--266
1992
Michael
Kearns
E#cient
noise­tolerant
learning
from
statistical
queries
Proceedings
Twenty­Fifth
Annual
Symposium
Theory
Computing
1993
Philip
Laird
Learning
from
Good
Data
Kluwer
international
series
engineering
com­
puter
science
Kluwer
Academic
Publishers
Boston
1988
Yasubumi
Sakakibara
Algorithmic
Learning
For­
Languages
Decision
Trees
thesis
Tokyo
Institute
Technology
October
1991
International
Institute
Advanced
Study
Social
Information
Science
Fujitsu
Laboratories
Research
Report
IIAS­RR­91­22E
Robert
Schapire
strength
weak
learnability
Machine
Learning
5(2):197--227
1990
Robert
Schapire
Design
Analysis
Ef­ficient
Learning
Algorithms
Press
Cambridge
1992
Hans
Ulrich
Simon
General
bounds
number
examples
needed
learning
probabilistic
concepts
Proceedings
Sixth
Annual
Workshop
Computational
Learning
Theory
Press
1993
Leslie
Valiant
theory
learnable
Commu­nications
27(11):1134--1142
November
1984