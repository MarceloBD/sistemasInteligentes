noise
detection
elimination
applied
noise
handling
chess
endgame
dragan
gamberger
nada
lavrac
rudjer
boskovic
institute
bijenicka
zagreb
croatia
gambi
lelhp
jozef
stefan
institute
jamova
ljubljana
slovenia
nada
lavrac
abstract
compression
measures
used
inductive
learners
such
measures
based
minimum
description
length
principle
provide
theoretically
justified
basis
grading
candidate
hypotheses
compression
based
induction
appropriate
also
handling
noisy
data
this
paper
shows
that
simple
compression
measure
used
detect
noisy
examples
technique
proposed
which
noisy
examples
detected
eliminated
from
training
hypothesis
then
built
from
remaining
examples
separation
noise
detection
hypothesis
formation
advantage
that
noisy
examples
influence
hypothesis
construction
opposed
most
standard
approaches
noise
handling
which
learner
typically
tries
avoid
overfitting
noisy
example
experimental
results
king
rook
king
chess
endgame
domain
show
potential
this
novel
approach
noise
handling
references
cestnik
bratko
estimating
probabilities
tree
pruning
proc
european
working
session
learning
clark
niblett
induction
algorithm
machine
learning
jong
spears
learning
concept
classification
rules
using
genetic
algorithms
proceedings
international
joint
conference
artificial
intelligence
ijcai
morgan
kaufmann
dzeroski
lavrac
inductive
learning
deductive
databases
ieee
transactions
knowledge
data
engineering
gamberger
minimization
approach
propositional
inductive
learning
proceeding
european
conference
machine
learning
ecml
springer
gamberger
specific
rule
induction
medical
domains
proc
computer
aided
data
analysis
medicine
cadam
scientific
publishing
gamberger
lavrac
towards
theory
relevance
inductive
concept
learning
technical
report
stefan
institute
ljubljana
gamberger
lavrac
dzeroski
noise
elimination
inductive
concept
learning
case
study
medical
diagnosis
proc
seventh
international
workshop
algorithmic
learning
theory
springer
press
lavrac
dzeroski
grobelnik
learning
nonrecursive
definitions
relations
with
linus
proc
fifth
european
working
session
learning
pages
springer
berlin
lavrac
dzeroski
inductive
learning
relations
from
noisy
examples
muggleton
inductive
logic
programming
academic
press
lavrac
dzeroski
inductive
logic
programming
technique
applications
ellis
horwood
simon
schuster
ellis
horwood
series
artificial
intelligence
chichester
lavrac
gamberger
dzeroski
approach
dimensionality
reduction
learning
from
deductive
databases
proceedings
international
workshop
inductive
logic
programming
technical
report
katholieke
universiteit
leuven
lavrac
dzeroski
bratko
handling
imperfect
data
inductive
logic
programming
raedt
advances
inductive
logic
programming
press
mingers
empirical
comparison
pruning
methods
decision
tree
induction
machine
learning
mingers
empirical
comparison
selection
measures
decision
tree
induction
machine
learning
muggleton
bain
hayes
michie
michie
experimental
comparison
human
machine
learning
formalisms
proc
sixth
international
workshop
machine
learning
morgan
kaufmann
mateo
muggleton
srinivasan
bain
compression
significance
accuracy
proc
international
conference
machine
learning
morgan
kaufmann
niblett
bratko
learning
decision
rules
noisy
domains
bramer
research
development
expert
systems
cambridge
university
press
quinlan
simplifying
decision
trees
international
journal
machine
studies
quinlan
learning
logical
definitions
from
relations
machine
learning
rissanen
modeling
shortest
data
description
automatica