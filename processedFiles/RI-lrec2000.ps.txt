Novelty­based
Evaluation
Method
Information
Retrieval
Atsushi
Fujii
Tetsuya
Ishikawa
University
Library
Information
Science
Kasuga
Tsukuba
305­8550
JAPAN
ffujii
ishikawag@ulis.ac.jp
Abstract
information
retrieval
research
precision
recall
have
long
been
used
evaluate
systems
However
given
that
number
retrieval
systems
resembling
another
already
available
public
valuable
retrieve
novel
relevant
documents
documents
that
cannot
retrieved
those
existing
systems
view
this
problem
propose
evaluation
method
that
favors
systems
retrieving
many
novel
documents
possible
also
used
method
evaluate
systems
that
participated
IREX
workshop
References
Keen
Michael
1992
Presenting
results
experi­mental
retrieval
comparisons
Information
Process­
Management
28(4):491--502
Mainichi
Shimbun
1994­1995
Mainichi
shimbun
94­'95
Japanese
Frei
1993
Concept
based
query
ex­pansion
Proceedings
16th
Annual
Inter­
national
SIGIR
Conference
Research
Development
Information
Retrieval
pages
Robertson
Walker
1994
Some
simple
effective
approximations
2­poisson
model
probabilistic
weighted
retrieval
Proceedings
17th
Annual
International
SIGIR
Confer­ence
Research
Development
Information
Retrieval
pages
232--241
Salton
Gerard
1992
state
retrieval
system
evaluation
Information
Processing
Management
28(4):441--449
Salton
Gerard
Christopher
Buckley
1988
Term­
weighting
approaches
automatic
text
retrieval
Information
Processing
Management
24(5):513
Sekine
Satoshi
Hitoshi
Isahara
1999
IREX
project
overview
Proceedings
IREX
Work­
shop
pages
7--12
Voorhees
Ellen
1998
Variations
relevance
judgments
measurement
retrieval
effec­tiveness
Proceedings
21sh
Annual
Inter­
national
SIGIR
Conference
Research
Development
Information
Retrieval
pages
Zobel
Justin
Alistair
Moffat
1998
Exploring
similarity
space
SIGIR
FORUM
32(1):18