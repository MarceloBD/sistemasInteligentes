Specification
Simulation
Statistical
Query
Algorithms
Eficiency
Noise
Tolerance
Javed
Aslam
Scott
Decatur
Aiken
Computation
Laboratory
Harvard
University
Cambridge
02138
Abstract
recent
innovation
computational
learning
theory
statistical
query
model
advantage
specify­ing
learning
algorithms
this
model
that
algorithms
simulated
model
both
absence
presence
noise
However
simulations
algo­rithms
model
have
non­optimal
time
sample
complexities
this
paper
introduce
method
specifying
statistical
query
algorithms
based
type
relative
error
provide
simulations
noise­free
noise­tolerant
models
which
yield
eficient
algorithms
Requests
estimates
statistics
this
model
take
form
Return
estimate
statistic
within
factor
return
promising
that
statistic
less
than
addition
showing
that
this
very
natural
lan­
guage
specifying
learning
algorithms
also
show
that
this
specification
polynomially
equivalent
standard
thus
known
learnability
hardness
results
statistical
query
learning
preserved
then
give
highly
eficient
simulations
relative
error
algorithms
show
that
learning
algorithms
obtained
simulating
eficient
relative
error
algorithms
both
absence
noise
presence
mali­cious
noise
have
roughly
optimal
sample
complexity
also
show
that
simulation
eficient
relative
error
algorithms
presence
classification
noise
yield
learn­ing
algorithms
least
eficient
those
obtained
through
standard
methods
some
cases
improved
roughly
op­timal
results
achieved
sample
complexities
these
simulations
based
metric
which
type
relative
error
metric
useful
quantities
which
small
even
zero
show
that
uniform
convergence
with
respect
metric
yields
uniform
convergence
with
respect
accuracy
Finally
while
show
that
many
specific
learning
al­gorithms
written
highly
eficient
relative
error
algorithms
also
show
fact
that
algorithms
written
eficiently
proving
general
upper
bounds
complexity
queries
function
accuracy
parameter
consequence
this
result
give
gen­eral
upper
bounds
complexity
learning
algorithms
achieved
through
relative
error
algorithms
simulations
described
above
References
Javed
Aslam
Scott
Decatur
General
bounds
statistical
query
learning
learning
with
noise
hypothesis
boosting
Proceedings
An­nual
Symposium
Foundations
Computer
Science
pages
282--291
November
1993
appear
Informa­tion
Computation
Javed
Aslam
Scott
Decatur
general
lower
bound
sample
complexity
learning
pres­ence
classification
noise
preparation
1994
Avrim
Blum
Merrick
Furst
Je#ery
Jackson
Michael
Kearns
Yishay
Mansour
Steven
Rudich
Weakly
learning
characterizing
statistical
query
learn­ing
using
Fourier
analysis
Proceedings
Annual
Symposium
Theory
Computing
1994
Anselm
Blumer
Andrzej
Ehrenfeucht
David
Haus­sler
Manfred
Warmuth
Learnability
Vapnik­Chervonenkis
dimension
Journal
36(4):929--865
1989
Scott
Decatur
Statistical
queries
faulty
acles
Proceedings
Sixth
Annual
Work­
shop
Computational
Learning
Theory
pages
Press
July
1993
Scott
Decatur
Learning
hybrid
noise
environments
using
statistical
queries
appear
Proccedings
Fifth
International
Workshop
Artificial
Intelligence
Statistics
January
1995
Scott
Decatur
Rosario
Gennaro
learning
from
noisy
incomplete
examples
Proceedings
Eigth
Annual
Workshop
Computational
Learn­
Theory
Press
July
1995
Andrzej
Ehrenfeucht
David
Haussler
Michael
Kearns
Leslie
Valiant
general
lower
bound
num­ber
examples
needed
learning
Information
Computation
82(3):247--251
September
1989
Yoav
Freund
Boosting
weak
learning
algorithm
majority
Proceedings
Third
Annual
Work­shop
Computational
Learning
Theory
pages
Morgan
Kaufmann
1990
Yoav
Freund
improved
boosting
algorithm
implications
learning
complexity
Proceedings
Fifth
Annual
Workshop
Computational
Learning
Theory
pages
391--398
Press
1992
David
Haussler
Decision
theoretic
generalizations
model
neural
other
learning
ap­plications
Information
Computation
100:78--150
1992
Michael
Kearns
E#cient
noise­tolerant
learning
from
statistical
queries
Proceedings
Annual
Symposium
Theory
Computing
pages
392--401
Diego
1993
Michael
Kearns
Ming
Learning
presence
malicious
errors
Proceedings
Annual
Symposium
Theory
Computing
Chicago
Illinois
1988
Philip
Laird
Learning
from
Good
Data
Kluwer
international
series
engineering
computer
science
Kluwer
Academic
Publishers
Boston
1988
Pollard
Rates
uniform
almost­sure
convergence
empirical
processes
indexed
unbounded
classes
functions
Manuscript
1986
Robert
Schapire
strength
weak
learnability
Ma­chine
Learning
5(2):197--226
1990
Leslie
Valiant
theory
learnable
Communica­tions
27(11):1134--1142
November
1984